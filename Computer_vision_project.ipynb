{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MILoKhtArhWF"
      },
      "source": [
        "# Face Detection System - ProCam S.p.A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZf43DOmNqTM"
      },
      "source": [
        "## Contesto & Obiettivi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5xw7H0ErdW2"
      },
      "source": [
        "Contesto: La ProCam S.p.A. è pronta a lanciare una nuova fotocamera digitale compatta, accessibile e pensata per i giovani appassionati di fotografia. L'obiettivo principale del prodotto è facilitare l'esperienza di scatto, in particolare per i selfie con una o più persone.\n",
        "\n",
        "Sfida: Sei stato assunto come Data Scientist per sviluppare un sistema di rilevamento volti nelle immagini, che aiuterà i tecnici a ottimizzare automaticamente le impostazioni della fotocamera durante i selfie. Il tuo compito è realizzare una pipeline che identifichi i volti presenti nelle immagini e restituisca le coordinate dei bounding box dove i volti sono individuati. Se non ci sono volti, la pipeline restituirà una lista vuota. Si tratta di un problema di Computer Vision, più precisamente di Face Detection.\n",
        "\n",
        "Obiettivo: Costruire un sistema di rilevamento dei volti utilizzando Scikit-learn. La pipeline deve essere in grado di:\n",
        "\n",
        "Prendere un’immagine in ingresso.\n",
        "Restituire una lista di coordinate dei bounding box dove sono presenti volti.\n",
        "Restituire una lista vuota se nell’immagine non ci sono volti."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68IhA82S7bk1"
      },
      "source": [
        "Lista articoli di documentazione:\n",
        "\n",
        "Creating a Face Recognition system from scratch. Computer Vision with Python | A basic/intuitive approach. https://medium.com/@juanlux7/creating-a-face-recognition-system-from-scratch-83b709cd0560\n",
        "\n",
        "FACIAL FEATURE EXTRACTION TECHNIQUES FOR FACE RECOGNITION https://thescipub.com/pdf/jcssp.2014.2360.2365.pdf\n",
        "\n",
        "Real-Time Face Detection with HOG and SVM https://www.eeweb.com/real-time-face-detection-and-recognition-with-svm-and-hog-features/\n",
        "\n",
        "Facial Expression Recognition Based on Facial\n",
        "Components Detection and HOG Features https://cedus.it/files/3ZChi_ACV-1.pdf\n",
        "\n",
        "OpenCV Haar Cascades https://pyimagesearch.com/2021/04/12/opencv-haar-cascades/\n",
        "\n",
        "Performance Analysis of Face Detection by using\n",
        "Viola-Jones algorithm https://www.ripublication.com/ijcir17/ijcirv13n5_05.pdf\n",
        "\n",
        "Face Detection using Haar Cascades https://docs.opencv.org/4.x/d2/d99/tutorial_js_face_detection.html\n",
        "\n",
        "The Viola/Jones Face Detector https://www.cs.ubc.ca/~lowe/425/slides/13-ViolaJones.pdf\n",
        "\n",
        "ALTRO: (possibili metodologie alternative)\n",
        "Object Detection with ssd, Faster RCNN, yolo https://medium.com/@javadghasemi7/object-detection-with-ssd-faster-rcnn-yolo-ce29b5c6a045"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hYiniyTrrW9"
      },
      "source": [
        "## Collegamento a kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "K4X1DB_ur2B0",
        "outputId": "6e7bec6c-a628-4afa-d284-f31c6731e530"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "from google.colab import files\n",
        "files.upload()  # carica il file kaggle.json\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# Librerie base\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from tqdm import tqdm  # per le progress bar\n",
        "\n",
        "# Per visualizzazione immagini in Colab\n",
        "from IPython.display import Image, display\n",
        "# Cerchiamo i dataset esatti\n",
        "!kaggle datasets list -s \"face recognition pins\"\n",
        "!kaggle datasets list -s \"face detection images\"\n",
        "!kaggle datasets list -s \"face emotions\"\n",
        "# Creiamo una directory per i dataset\n",
        "!mkdir -p face_datasets\n",
        "\n",
        "# 1. Pins Face Recognition\n",
        "!kaggle datasets download hereisburak/pins-face-recognition -p face_datasets --unzip\n",
        "\n",
        "# 2. Face Detection in Images\n",
        "!kaggle datasets download dataturks/face-detection-in-images -p face_datasets --unzip\n",
        "\n",
        "# 3. Human Face Emotions\n",
        "!kaggle datasets download sanidhyak/human-face-emotions -p face_datasets --unzip\n",
        "\n",
        "# Verificare i contenuti scaricati\n",
        "!ls face_datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYhX8ECrr8i5"
      },
      "source": [
        "## Configurazione iniziale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_kIw690RsBuX"
      },
      "outputs": [],
      "source": [
        "#LIBRERIE\n",
        "import numpy as np\n",
        "import cv2\n",
        "import joblib\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV, learning_curve\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "#COSTANTI GLOBALI\n",
        "TARGET_SIZE = (24, 24)\n",
        "MAX_IMAGES = 5000\n",
        "NEG_IMAGES = 2000\n",
        "TEST_IMAGES = 3\n",
        "BATCH_SIZE = 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIRE4fvgsJPI"
      },
      "source": [
        "## Funzioni di caricamento dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d9BaevajsOzA"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_images(directory, max_images=MAX_IMAGES):\n",
        "    \"\"\"Carica e preprocessa le immagini per training.\"\"\"\n",
        "    images = []\n",
        "    files_processed = 0\n",
        "\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if files_processed >= max_images:\n",
        "            break\n",
        "\n",
        "        for file in tqdm(files, desc=f\"Caricamento {os.path.basename(root)}\"):\n",
        "            if files_processed >= max_images:\n",
        "                break\n",
        "\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                img_path = os.path.join(root, file)\n",
        "                image = load_image(img_path)\n",
        "\n",
        "                if image is not None:\n",
        "                    processed = preprocess_image_hog(image)\n",
        "                    if processed is not None:\n",
        "                        images.append(processed)\n",
        "                        images.append(cv2.flip(processed, 1))\n",
        "                        files_processed += 2\n",
        "\n",
        "    return images\n",
        "\n",
        "def create_negative_samples(size=TARGET_SIZE, n_samples=NEG_IMAGES):\n",
        "    \"\"\"Genera campioni negativi per training.\"\"\"\n",
        "    negatives = []\n",
        "    patterns = [\n",
        "        lambda: np.random.randint(0, 255, size=size, dtype=np.uint8),\n",
        "        lambda: np.linspace(0, 255, size[0]*size[1]).reshape(size).astype(np.uint8),\n",
        "        lambda: np.fromfunction(lambda i, j: ((i+j)/2) % 255, size).astype(np.uint8)\n",
        "    ]\n",
        "\n",
        "    for _ in tqdm(range(n_samples), desc=\"Generazione negativi\"):\n",
        "        pattern = np.random.choice(patterns)()\n",
        "        negatives.append(pattern)\n",
        "\n",
        "    return negatives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4kqTj1KsVJ3"
      },
      "source": [
        "## Preprocessing immagini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66wZxmZHstOf"
      },
      "source": [
        "Questa sezione implementa due diversi approcci di preprocessing:\n",
        "\n",
        "1. Viola-Jones Preprocessing: Equalizza, migliora il contrasto dell'immagine e mantiene le dimensioni originali\n",
        "\n",
        "2. HOG Preprocessing: Usa equalizzazione adattiva CLAHE (Contrast Limited Adaptive Histogram Equalization) e ridimensiona l'immagine a una dimensione target fissa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9xlWv2lasYxp"
      },
      "outputs": [],
      "source": [
        "# ===== 1. ACQUISIZIONE IMMAGINE =====\n",
        "def load_image(image_path):\n",
        "    \"\"\"Carica e prepara l'immagine iniziale.\"\"\"\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    return image\n",
        "\n",
        "# ===== 2. PRE-PROCESSING =====\n",
        "def preprocess_image_viola_jones(image):\n",
        "    \"\"\"Preprocessing per Viola-Jones.\"\"\"\n",
        "    if image is None:\n",
        "        return None\n",
        "    return cv2.equalizeHist(image)\n",
        "\n",
        "def preprocess_image_hog(image, target_size=TARGET_SIZE):\n",
        "    \"\"\"Preprocessing per HOG.\"\"\"\n",
        "    if image is None:\n",
        "        return None\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    equalized = clahe.apply(image)\n",
        "    return cv2.resize(equalized, target_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgDfaAvyt5q7"
      },
      "source": [
        "## Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNdzVhXBs20f"
      },
      "source": [
        "Implementa i due metodi distinti di face detection:\n",
        "\n",
        "Viola-Jones Detection:\n",
        "\n",
        "Algoritmo che usa il classificatore cascade di Haar e funziona bene per volti frontali. Utilizza features rettangolari che analizzano differenze di intensità tra regioni adiacenti. E' efficace per catturare caratteristiche del volto come:\n",
        "\n",
        "- Regione degli occhi più scura rispetto alle guance\n",
        "\n",
        "- Ponte nasale più chiaro rispetto agli occhi\n",
        "\n",
        "- Labbra più scure rispetto al mento\n",
        "\n",
        "\n",
        "\n",
        "HOG Detection:\n",
        "\n",
        "HOG è un descrittore di feature che viene combinato con AdaBoost per la classificazione includendo una fase di training e utilizza sliding window e scale pyramid per la detection\n",
        "\n",
        "Infine la funzione non_max_suppression gestisce il raffinamento finale delle detection eliminando le detection ridondanti, selezionando il bounding box più grande come detection principale, ritornando le coordinate per il disegno del rettangolo\n",
        "\n",
        "visualize_detections mostra quindi i risultati della detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MxzdVe35t9cr"
      },
      "outputs": [],
      "source": [
        "#DETECTION\n",
        "def detect_faces_viola_jones(image, scale_factor=1.1, min_neighbors=8, min_size=(80, 80)):\n",
        "    \"\"\"Rileva volti usando Viola-Jones.\"\"\"\n",
        "    if image is None:\n",
        "        return []\n",
        "\n",
        "    face_cascade = cv2.CascadeClassifier(\n",
        "        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "    )\n",
        "\n",
        "    processed = preprocess_image_viola_jones(image)\n",
        "    faces = face_cascade.detectMultiScale(\n",
        "        processed,\n",
        "        scaleFactor=scale_factor,\n",
        "        minNeighbors=min_neighbors,\n",
        "        minSize=min_size\n",
        "    )\n",
        "\n",
        "    return faces if len(faces) > 0 else []\n",
        "\n",
        "def compute_hog_features(image):\n",
        "    \"\"\"Calcola le feature HOG.\"\"\"\n",
        "    hog = cv2.HOGDescriptor((24,24), (8,8), (4,4), (8,8), 9)\n",
        "    features = hog.compute(image)\n",
        "    return features.flatten()\n",
        "\n",
        "def train_hog_detector(positive_dir, n_negative=NEG_IMAGES):\n",
        "   \"\"\"\n",
        "   Addestra il detector HOG con ricerca parametri e validazione completa.\n",
        "   \"\"\"\n",
        "   # Carica e prepara i dati\n",
        "   print(\"1. Caricamento e preprocessing dati...\")\n",
        "   pos_images = load_and_preprocess_images(positive_dir)\n",
        "   neg_images = create_negative_samples(n_samples=n_negative)\n",
        "\n",
        "   # Estrai features\n",
        "   print(\"\\n2. Estrazione features HOG...\")\n",
        "   X_pos = np.array([compute_hog_features(img) for img in tqdm(pos_images, desc='HOG positivi')])\n",
        "   X_neg = np.array([compute_hog_features(img) for img in tqdm(neg_images, desc='HOG negativi')])\n",
        "\n",
        "   X = np.vstack([X_pos, X_neg])\n",
        "   y = np.hstack([np.ones(len(X_pos)), np.zeros(len(X_neg))])\n",
        "\n",
        "   print(f\"\\nDimensioni dataset:\")\n",
        "   print(f\"- Esempi positivi: {len(X_pos)}\")\n",
        "   print(f\"- Esempi negativi: {len(X_neg)}\")\n",
        "   print(f\"- Feature per esempio: {X.shape[1]}\")\n",
        "\n",
        "   # Split del dataset\n",
        "   X_train, X_test, y_train, y_test = train_test_split(\n",
        "       X, y, test_size=0.2, random_state=42, stratify=y\n",
        "   )\n",
        "\n",
        "   # Parametri per grid search\n",
        "   param_grid = {\n",
        "       'estimator__max_depth': [2, 3],\n",
        "       'n_estimators': [100, 300],\n",
        "       'learning_rate': [0.01, 0.1]\n",
        "   }\n",
        "\n",
        "   # Base model\n",
        "   base_model = AdaBoostClassifier(\n",
        "       estimator=DecisionTreeClassifier(),\n",
        "       random_state=42\n",
        "   )\n",
        "\n",
        "   # Info Grid Search\n",
        "   n_combinations = len(param_grid['estimator__max_depth']) * \\\n",
        "                   len(param_grid['n_estimators']) * \\\n",
        "                   len(param_grid['learning_rate'])\n",
        "   n_folds = 5\n",
        "   total_fits = n_combinations * n_folds\n",
        "\n",
        "   print(f\"\\n3. Inizio Grid Search:\")\n",
        "   print(f\"- {n_combinations} combinazioni di parametri\")\n",
        "   print(f\"- {n_folds}-fold cross validation\")\n",
        "   print(f\"- {total_fits} fits totali\\n\")\n",
        "\n",
        "   # Custom scorer per tenere traccia del progresso\n",
        "   fit_params = {'current_fit': 0, 'total_fits': total_fits}\n",
        "\n",
        "   def custom_scorer(estimator, X, y, fit_params=fit_params):\n",
        "       fit_params['current_fit'] += 1\n",
        "       print(f\"\\rFit {fit_params['current_fit']}/{fit_params['total_fits']}\", end='')\n",
        "       return estimator.score(X, y)\n",
        "\n",
        "   # Grid Search\n",
        "   grid_search = GridSearchCV(\n",
        "       estimator=base_model,\n",
        "       param_grid=param_grid,\n",
        "       cv=n_folds,\n",
        "       n_jobs=1,  # Set a 1 per mantenere l'ordine\n",
        "       verbose=0,  # Riduciamo verbosità standard\n",
        "       scoring=custom_scorer\n",
        "   )\n",
        "\n",
        "   grid_search.fit(X_train, y_train)\n",
        "   print(\"\\n\") # Nuova riga dopo il completamento\n",
        "\n",
        "   # Risultati Grid Search\n",
        "   print(\"\\n4. Risultati Grid Search:\")\n",
        "   print(\"Migliori parametri trovati:\")\n",
        "   print(grid_search.best_params_)\n",
        "   print(f\"Miglior score: {grid_search.best_score_:.3f}\")\n",
        "\n",
        "   # Modello migliore\n",
        "   best_model = grid_search.best_estimator_\n",
        "\n",
        "   # Valutazione sul test set\n",
        "   print(\"\\n5. Valutazione finale sul test set:\")\n",
        "   y_pred = best_model.predict(X_test)\n",
        "   print(\"\\nReport di classificazione:\")\n",
        "   print(classification_report(y_test, y_pred))\n",
        "\n",
        "   # Matrice di confusione\n",
        "   conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "   disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
        "                                display_labels=['Non-Volto', 'Volto'])\n",
        "   plt.figure(figsize=(8, 6))\n",
        "   disp.plot(cmap='Blues', values_format='d')\n",
        "   plt.title('Matrice di Confusione')\n",
        "   plt.show()\n",
        "\n",
        "   # Learning curves\n",
        "   train_sizes = np.linspace(0.1, 1.0, 5)\n",
        "   train_sizes, train_scores, val_scores = learning_curve(\n",
        "       best_model, X_train, y_train,\n",
        "       train_sizes=train_sizes, cv=3,\n",
        "       n_jobs=-1,\n",
        "       scoring='f1'\n",
        "   )\n",
        "\n",
        "   plt.figure(figsize=(10, 6))\n",
        "   plt.plot(train_sizes, np.mean(train_scores, axis=1), 'o-', label='Training score')\n",
        "   plt.plot(train_sizes, np.mean(val_scores, axis=1), 'o-', label='Cross-validation score')\n",
        "   plt.xlabel('Training examples')\n",
        "   plt.ylabel('Score')\n",
        "   plt.title('Learning Curves')\n",
        "   plt.legend(loc='best')\n",
        "   plt.grid(True)\n",
        "   plt.show()\n",
        "\n",
        "   return best_model, grid_search.best_params_, grid_search.best_score_\n",
        "\n",
        "def detect_faces_hog(image, model, threshold=0.7):\n",
        "    \"\"\"Rileva volti usando HOG.\"\"\"\n",
        "    if image is None or model is None:\n",
        "        return []\n",
        "\n",
        "    height, width = image.shape\n",
        "    min_size = 50\n",
        "    scale_factor = 1.2\n",
        "    stride = 8\n",
        "    detections = []\n",
        "\n",
        "    # Scale pyramid\n",
        "    scales = []\n",
        "    current_scale = 1.0\n",
        "    while min(height * current_scale, width * current_scale) >= min_size:\n",
        "        scales.append(current_scale)\n",
        "        current_scale /= scale_factor\n",
        "\n",
        "    for scale in scales:\n",
        "        scaled_h = int(height * scale)\n",
        "        scaled_w = int(width * scale)\n",
        "        scaled_img = cv2.resize(image, (scaled_w, scaled_h))\n",
        "\n",
        "        for y in range(0, scaled_h - min_size, stride):\n",
        "            for x in range(0, scaled_w - min_size, stride):\n",
        "                window = cv2.resize(scaled_img[y:y + min_size, x:x + min_size], TARGET_SIZE)\n",
        "                features = compute_hog_features(window)\n",
        "\n",
        "                prob = model.predict_proba([features])[0][1]\n",
        "                if prob > threshold:\n",
        "                    real_x = int(x / scale)\n",
        "                    real_y = int(y / scale)\n",
        "                    real_size = int(min_size / scale)\n",
        "                    detections.append((real_x, real_y, real_size, real_size))\n",
        "\n",
        "    return non_max_suppression(detections) if detections else []\n",
        "\n",
        "#VIZ\n",
        "def non_max_suppression(boxes):\n",
        "    \"\"\"Applica non-maximum suppression.\"\"\"\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    boxes = np.array(boxes)\n",
        "    x1 = boxes[:,0]\n",
        "    y1 = boxes[:,1]\n",
        "    x2 = boxes[:,0] + boxes[:,2]\n",
        "    y2 = boxes[:,1] + boxes[:,3]\n",
        "    areas = (x2 - x1) * (y2 - y1)\n",
        "\n",
        "    largest_idx = np.argmax(areas)\n",
        "    return boxes[largest_idx:largest_idx+1].astype(int)\n",
        "\n",
        "def visualize_detections(image, detections, title):\n",
        "    \"\"\"Visualizza i risultati della detection.\"\"\"\n",
        "    img_copy = cv2.cvtColor(image.copy(), cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    for (x, y, w, h) in detections:\n",
        "        cv2.rectangle(img_copy, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(f'{title}: {len(detections)} volti')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUoU06zedoPR",
        "outputId": "b7ffb133-8579-454d-8b78-b77e152b0117"
      },
      "outputs": [],
      "source": [
        "# Definizione del percorso del dataset\n",
        "dataset_dir = os.path.join('face_datasets', '105_classes_pins_dataset')\n",
        "\n",
        "# Verifica che il percorso esista\n",
        "if not os.path.exists(dataset_dir):\n",
        "    raise ValueError(f\"Dataset non trovato in: {dataset_dir}\")\n",
        "\n",
        "print(f\"Utilizzo dataset da: {dataset_dir}\")\n",
        "\n",
        "# Esecuzione del training con validazione\n",
        "best_model, best_params, best_score = train_hog_detector(dataset_dir)\n",
        "\n",
        "# Stampa dei risultati finali\n",
        "print(\"\\nRisultati finali:\")\n",
        "print(\"Migliori parametri:\", best_params)\n",
        "print(\"Miglior score:\", best_score)\n",
        "\n",
        "# Test su alcune immagini\n",
        "test_images = []\n",
        "for root, _, files in os.walk(dataset_dir):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            test_images.append(os.path.join(root, file))\n",
        "            if len(test_images) >= 5:  # Test su 5 immagini\n",
        "                break\n",
        "    if len(test_images) >= 5:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUGVwZncHXjt"
      },
      "source": [
        "Il modello ha dimostrato ottime performance nella fase di test, raggiungendo un'accuratezza del 99% sia per il riconoscimento dei volti che dei non-volti. In particolare, la matrice di confusione rivela che su un totale di 1400 immagini di test, il sistema ha correttamente identificato 996 volti e 394 non-volti, commettendo solo 10 errori in totale (6 falsi positivi e 4 falsi negativi). Questi numeri testimoniano la robustezza e l'affidabilità del classificatore."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgZKNZnBuKAu"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PXalfLbeuMpT",
        "outputId": "27b12adb-955a-42f8-9307-7121b30e09a9"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "   \"\"\"Pipeline principale per confronto face detection.\"\"\"\n",
        "   print(\"=== Creazione e Training Modello HOG+AdaBoost ===\")\n",
        "\n",
        "   # Crea il modello con i parametri ottimali trovati\n",
        "   hog_model = AdaBoostClassifier(\n",
        "       estimator=DecisionTreeClassifier(max_depth=3),\n",
        "       n_estimators=300,\n",
        "       learning_rate=0.1\n",
        "   )\n",
        "\n",
        "   # Carica e prepara i dati\n",
        "   print(\"\\n1. Caricamento dati...\")\n",
        "   positive_dir = os.path.join('face_datasets', '105_classes_pins_dataset')\n",
        "   pos_images = load_and_preprocess_images(positive_dir)\n",
        "   neg_images = create_negative_samples()\n",
        "\n",
        "   # Estrai features\n",
        "   print(\"\\n2. Estrazione features...\")\n",
        "   X_pos = np.array([compute_hog_features(img) for img in tqdm(pos_images, desc='HOG positivi')])\n",
        "   X_neg = np.array([compute_hog_features(img) for img in tqdm(neg_images, desc='HOG negativi')])\n",
        "\n",
        "   X = np.vstack([X_pos, X_neg])\n",
        "   y = np.hstack([np.ones(len(X_pos)), np.zeros(len(X_neg))])\n",
        "\n",
        "   # Training\n",
        "   print(\"\\n3. Training modello...\")\n",
        "   hog_model.fit(X, y)\n",
        "   print(\"Training completato!\")\n",
        "\n",
        "   # Test comparativo\n",
        "   print(\"\\n=== Test Comparativo ===\")\n",
        "   test_dir = os.path.join('face_datasets', '105_classes_pins_dataset')\n",
        "\n",
        "   # Raccogli immagini test\n",
        "   all_images = []\n",
        "   for root, _, files in os.walk(test_dir):\n",
        "       for file in files:\n",
        "           if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "               all_images.append(os.path.join(root, file))\n",
        "               if len(all_images) >= TEST_IMAGES:\n",
        "                   break\n",
        "       if len(all_images) >= TEST_IMAGES:\n",
        "           break\n",
        "\n",
        "   if all_images:\n",
        "       print(f\"\\nTest su {TEST_IMAGES} immagini casuali...\")\n",
        "       selected_images = np.random.choice(\n",
        "           all_images,\n",
        "           size=min(TEST_IMAGES, len(all_images)),\n",
        "           replace=False\n",
        "       )\n",
        "\n",
        "       for image_path in selected_images:\n",
        "           print(f\"\\nTest su: {os.path.basename(image_path)}\")\n",
        "           image = load_image(image_path)\n",
        "\n",
        "           if image is not None:\n",
        "               # Test Viola-Jones\n",
        "               vj_faces = detect_faces_viola_jones(image)\n",
        "               visualize_detections(image, vj_faces, \"Viola-Jones\")\n",
        "\n",
        "               # Test HOG\n",
        "               hog_faces = detect_faces_hog(image, hog_model)\n",
        "               visualize_detections(image, hog_faces, \"HOG + AdaBoost\")\n",
        "   else:\n",
        "       print(\"Nessuna immagine trovata per il test\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "   main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm2MlCRn_pii"
      },
      "source": [
        "## Conclusioni"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9R0p8xZ18T"
      },
      "source": [
        "Durante lo sviluppo del progetto per ProCam S.p.A., ho seguito la consegna implementando un sistema di face detection utilizzando scikit-learn, costruendo da zero un modello basato su HOG per l'estrazione delle feature e AdaBoost per la classificazione. Il modello custom ha dimostrato buone performance, riuscendo a rilevare efficacemente i volti nelle immagini di test.\n",
        "Per curiosità e confronto, abbiamo anche sperimentato con il modello Viola-Jones pre-addestrato disponibile in OpenCV. Seppur più preciso a rilevare le coordinate dei volti, il modello pre-addestrato in alcuni casi sbaglia a classificare se si tratta o meno di un volto, cosa che invece riesce bene al modello addestrato from scratch.\n",
        "I risultati dei test hanno mostrato che entrambi gli approcci funzionano efficacemente per il caso d'uso dei selfie."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1hYiniyTrrW9",
        "iYhX8ECrr8i5",
        "YIRE4fvgsJPI",
        "W4kqTj1KsVJ3"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
